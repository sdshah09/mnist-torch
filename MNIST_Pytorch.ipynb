{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvpxgrGblmPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = torch.load(\"/training.pt\")\n",
        "x[59000].shape,y.shape # X have 60k images with shape 28*28 and y have 60k labels associated with it\"\n",
        "y[59000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQYCxE0zmZEf",
        "outputId": "93f33623-50d1-4242-ca09-3d9f8c9e7220"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x[59000].numpy())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "lxEfiFBVmjjM",
        "outputId": "d26000c8-997b-42c2-f9e8-24021cdfadf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" We need to use hot encoding to convert the numerical representation of data into binary i.e. one hot encoding to classify them into 10 classes because we have a range of\n",
        "n numbers of 0 to 9. We have 60000 images with the represnetation of handwritten 0 to 9 values with 60000 labels.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "UnWcqKfPnRR2",
        "outputId": "4855517a-7181-4c1c-b456-f942fbb1e6fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' We need to use hot encoding to convert the numerical representation of data into binary i.e. one hot encoding to classify them into 10 classes because we have a range of\\nn numbers of 0 to 9. We have 60000 images with the represnetation of handwritten 0 to 9 values with 60000 labels.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = F.one_hot(y,num_classes=10)\n",
        "y_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYNMG1I1vBh6",
        "outputId": "ced62201-f3be-471f-8d2b-4fd1d4691f31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ5U2vQqvKfa",
        "outputId": "018987eb-f581-47b7-8929-6bbe6fb28abb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we need to flatten the image which is 28*28 because we need them in vector form so we will multiply them and create into single 784 vector size"
      ],
      "metadata": {
        "id": "sMpFGaVVvL_G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.view(-1,28**2).shape # -1 means let the 60000 be as it is and change the vector form of 28*28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnSC7z45vovR",
        "outputId": "4ef190d4-2122-4a14-9fbc-76028c8111a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Dataset Object"
      ],
      "metadata": {
        "id": "xlT8Fcz6vyP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CTDataset(Dataset):\n",
        "  def __init__(self,filepath):\n",
        "    self.x,self.y = torch.load(filepath)\n",
        "    self.x = self.x/255 # This is done because the color of a pixel ranges between 0 to 255 and dividing by 255 will give the value between 0 and 1 which will be easier to calculate\n",
        "    self.y = F.one_hot(self.y,num_classes=10).to(float)\n",
        "  def __len__(self):\n",
        "    return self.x.shape[0]\n",
        "  def __getitem__(self,ix):\n",
        "    return self.x[ix],self.y[ix]"
      ],
      "metadata": {
        "id": "lnH_QCOh1uRO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = CTDataset(\"/training.pt\")\n",
        "test_ds = CTDataset(\"/test.pt\")"
      ],
      "metadata": {
        "id": "mPNM_9HV3B3l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds) # Works due to __len__  function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_1XyqRG3MqP",
        "outputId": "94f5129d-ae00-435f-d349-736759d9fc50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZlSdhMk6pZr",
        "outputId": "55ab9ec1-9a11-4d77-9a1b-631022e713d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]# Works due to __getitem__ function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUEq1aB_6qYP",
        "outputId": "64dda0a0-630b-419b-f212-930061787e1c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333,\n",
              "          0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
              "          0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "          0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843,\n",
              "          0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
              "          0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667,\n",
              "          0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922,\n",
              "          0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882,\n",
              "          0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765,\n",
              "          0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
              "          0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922,\n",
              "          0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882,\n",
              "          0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
              "          0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588,\n",
              "          0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922,\n",
              "          0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314,\n",
              "          0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000]]),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs,ys = train_ds[0:4]"
      ],
      "metadata": {
        "id": "-jOCbv9Z6uJ9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape,ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqDWcVfW65lU",
        "outputId": "4d21bfd6-3128-463b-d71c-f4f045cb6ff6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 28, 28]), torch.Size([4, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_ds,batch_size=5)"
      ],
      "metadata": {
        "id": "DAh0t7QJ66qP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in train_dl:\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  break\n",
        "# There are 12000 different mini batches having batch size of 5 for each mini batch because of parameter of batch_size parameter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8QVvtQZ7IQr",
        "outputId": "cd639bfb-1d51-4c0d-e104-c50604e83bd2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 28, 28])\n",
            "torch.Size([5, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC6LNtlN7Mqr",
        "outputId": "1fd6d20e-7617-4a0a-a3a9-c9f0819497e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Entropy Loss"
      ],
      "metadata": {
        "id": "NP3IBpEf7dU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "q_JDhp6F7hpI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Network"
      ],
      "metadata": {
        "id": "_exyxwOM7lcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTNeural(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.matrix1 = nn.Linear(28**2,100)\n",
        "    self.matrix2 = nn.Linear(100,50)\n",
        "    self.matrix3 = nn.Linear(50,10)\n",
        "    self.R = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    # print(\"Hi\")\n",
        "    x = x.view(-1,28**2)\n",
        "    x = self.matrix3(self.R(self.matrix2(self.R(self.matrix1(x)))))\n",
        "    return x.squeeze()"
      ],
      "metadata": {
        "id": "o1o5Q6wL7nvH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = MNISTNeural()"
      ],
      "metadata": {
        "id": "dv9SybWU_pJU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtJsgaOBCe9n",
        "outputId": "3d5e2742-1154-4626-fa66-7ebec6280461"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f(xs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfk7zJdyCmUg",
        "outputId": "581ccb67-da94-40a6-a00c-99fb0ee842e0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1128, -0.1479,  0.1793, -0.0487, -0.0413,  0.0703, -0.0829, -0.0524,\n",
              "          0.0616,  0.0121],\n",
              "        [ 0.1034, -0.1428,  0.1332, -0.0071, -0.0443,  0.0589, -0.0976, -0.0753,\n",
              "          0.0821,  0.0141],\n",
              "        [ 0.0922, -0.1480,  0.1387,  0.0100, -0.0028,  0.0217, -0.1328, -0.0924,\n",
              "          0.0726,  0.0570],\n",
              "        [ 0.0492, -0.1303,  0.1490, -0.0340,  0.0025,  0.0448, -0.1050, -0.0769,\n",
              "          0.0570,  0.0359]], grad_fn=<SqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys # We have to create a model in such a way that value of xs = ys. Meaning training xs to get the value of ys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLm4Or-xCuwD",
        "outputId": "6bd512b8-a412-4d38-fb08-1b6b347f0a06"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = L(f(xs),ys)  # Running cross entropy loss function to minimize loss in xs to get value near to ys.\n",
        "# We have to adjust the weights of to get the L variable as small as possible i.e. minimizing loss\n",
        "loss.backward()\n",
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPyw6AMND3Yx",
        "outputId": "a61e89ef-c6c5-42eb-a5a5-6fd67334b339"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2987483739852905"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dl,f,n_epochs=20): # dl = Dataloader (mini batches), f = Neural network class\n",
        "  opt = SGD(f.parameters(),lr = 0.01)\n",
        "  L = nn.CrossEntropyLoss() # For Optimization\n",
        "\n",
        "  losses = []\n",
        "  epochs = []\n",
        "  for epoch in range(n_epochs): # So in each epoch the 12000 batches will get trained i.e. 20*12000 time\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "    N = len(dl)\n",
        "    for i,(x,y) in enumerate(dl): # Loop 12000 times because taken mini batch size = 5 so 60000 images/5 = 12000 mini batches\n",
        "      opt.zero_grad()\n",
        "      loss_value = L(f(x),y)\n",
        "      loss_value.backward()\n",
        "      opt.step()\n",
        "\n",
        "      #Store the training data\n",
        "      epochs.append(epoch+i/N)\n",
        "      losses.append(loss_value.item())\n",
        "  return np.array(epochs),np.array(losses)"
      ],
      "metadata": {
        "id": "pU4mKpgeESwG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_data,loss_data = train_model(train_dl,f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onpiAjxiHpTa",
        "outputId": "6d349e1b-113f-4839-82c4-bd2efcbfb118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Epoch: 1\n",
            "Epoch: 2\n",
            "Epoch: 3\n",
            "Epoch: 4\n",
            "Epoch: 5\n",
            "Epoch: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_data,loss_data)\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Cross Entropy (per batch)')\n"
      ],
      "metadata": {
        "id": "IlFaH3yfH--Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(epoch_data)"
      ],
      "metadata": {
        "id": "onVZ-LmdJzby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(loss_data)"
      ],
      "metadata": {
        "id": "ivyDCqJKKETU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Each one of these data points corresponds to the loss evaluated on a batch of 5 images.\n",
        "An entire epoch is 60000 images. We can average the loss accros all the data per epoch to get the loss for all 60000 images\n",
        "* Since there are 20 total epochs, we split the array above into 20 equal portions and take the mean of each portion"
      ],
      "metadata": {
        "id": "mniw-2KWKH8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_data_avg = epoch_data.reshape(20,-1).mean(axis=1)\n",
        "loss_data_avg = loss_data.reshape(20,-1).mean(axis=1)"
      ],
      "metadata": {
        "id": "YqMGFkKoLldr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epoch_data_avg, loss_data_avg,'o--')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Cross Entropy (avgd per epoch)')\n"
      ],
      "metadata": {
        "id": "vBnOi1j0Lvpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_sample = train_ds[0][1]\n",
        "y_sample"
      ],
      "metadata": {
        "id": "1XPKfN9OLxKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sample = train_ds[0][0]\n",
        "x_sample\n",
        "yhat_sample = f(x_sample)\n",
        "yhat_sample"
      ],
      "metadata": {
        "id": "AE3dCjNFL_Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get what image this is, we should really be taking the index of the maximum value\n",
        "\n",
        "torch.argmax(yhat_sample)"
      ],
      "metadata": {
        "id": "Jdlnus_BL8pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_sample)"
      ],
      "metadata": {
        "id": "aN8pR4OGOEkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = train_ds[0:2000]\n",
        "yhats = f(xs).argmax(axis=1)\n"
      ],
      "metadata": {
        "id": "2wB8Io_FOGrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(10,4,figsize=(10,15))\n",
        "for i in range(40):\n",
        "    plt.subplot(10,4,i+1)\n",
        "    plt.imshow(xs[i])\n",
        "    plt.title(f'Predicted Digit: {yhats[i]}')\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BamfMBfuOKy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs, ys = test_ds[:2000]\n",
        "yhats = f(xs).argmax(axis=1)\n"
      ],
      "metadata": {
        "id": "agy9k3srOQEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(10,4,figsize=(10,15))\n",
        "for i in range(40):\n",
        "    plt.subplot(10,4,i+1)\n",
        "    plt.imshow(xs[i])\n",
        "    plt.title(f'Predicted Digit: {yhats[i]}')\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y527sEsTOVeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtY4hMRTOWDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}